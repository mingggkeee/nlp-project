{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd06ba75201ffc980e63fafb5fcc34cd5fa109d6a791497ca89853d5cb86fd40001",
   "display_name": "Python 3.7.10 64-bit ('ssac': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = pd.read_csv('1st_keyword.csv')\n",
    "second_df = pd.read_csv('2nd_keyword.csv')\n",
    "third_df = pd.read_csv('3rd_keyword.csv')\n",
    "wt_df = pd.read_csv('정식웹툰댓글키워드.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_group = ['싱글맘맘이야', '여우자매', '대학원 탈출일지', '오사와 오폐수들', '저승파견고용직', '우리 카페 사장님이 이상하다', '괜찮아, 고3이야', '우리집 강아지는 복슬강아지', '지극히 평범한 생활', '아빠는 N살', '낮잠 자는 사람들', '깜빡깜빡', '루텔', '구나의 그랬구나', '아스테리스크', '아오링도쿄', '잔액이 부족합니다', '운명...인가요?', '발버둥치다', '국제결혼개그만화', '실험학교', '오늘을 담다.', '방구석수필', '좀비 패밀리', '(Old)악마법소녀', '서툴고 어리숙해도 좋아하는', '정령왕즈', '쿤도덥브라더스', '생각보다 잘 자랐습니다', '몬스터 커맨더F', '생존일지', '시크릿가족', '무엇이든 그려드립니닷!', '카나와 초나의 독일', '그래도 하루는', '죽음과 동화', '감각의 어빌러티', '천상대전', 'AI폰 아리랑', '채채쓰의 웃픈일기', '방에 콕! 진댕', '무존재감']\n",
    "\n",
    "second_group = ['서폿저택에 어서오세요', '밤을 거둔 신기루는', '수영만화일기', '아틀레냐 비바체', '홈 스윗 홈', '뿅가이', '나랑노랑~이제는 괜찮은 이야기', '젤라 유니버스', '클리셰', '결혼하고 싶지 않았는데 못하게 되었다.', '86\\'d', '리드래프트', '틈', '산군대잔치', '행복을 찾다.', '김작가의 오춘기 그림일기', '포로롱 포롱', '우리 가 꿈', '올어바웃 You', '엑스프렌즈', '언니가 돌아왔다', '나는 마요 집사로소이다', '맹랑맘마 MEMORY', '오늘도 그래고래', '중간계 사우나', '러브 유어 시스터', '양송부부의 맛있는 한잔', '행복을 만드는 방법', '내 룸메이트는 마네킹', '죽 쑨 만화', '두꺼비집', '제제와 함께', '과학고 생존일지', '느린한끼', '나부활', '여긴 불빛이 안 드는 곳이야', '타챠노트', '사랑하는 제자들', '프라이머리 컬러', '생산직 툰', '눈치없는 내 친구!', '분노의 난임일기', '러브 햄츄얼리', '런어웨이', '만화 임진왜란', '오무라이스 프로젝트', '너구리네 육아일기', '이과지옥', 'LADS\\'PARTY', '미친 꽃은 답도 없다', '소라비의 잡화점']\n",
    "\n",
    "third_group = ['사는 게 이게 모양?!', '빨간 고백', '위닝샷!', '집순이에 대하여', '자작 보드게임 동아리', '500원 토끼', '솔의 일기', '이래봬도2학년', '대공녀는 거기에 없었다', '범고래아가씨', '77년생, 열아홉', '두남자일기', '여기서 한잔할래?', '좋아하는거 참으면 병나요!', '딴 짓이 제일 재밌어', '스토커의 하루', '띵동! 도토리에요', '마이데이', '판타지 TV', '만월에 핀 연꽃', '전지적덕후시점', '너와 나의 하늘색', '너와 가까워지는 거리', '어둠의 일상툰', '하이스쿨 콤플렉스(마이동풍)', '함께 할 때까지', '이세계 국밥 마스터', '우당탕 입큰이', '좀비랜드', '내 매력에 퐁당', '나타나주세요!', '하루의 하늘', '한 뼘 공포집', '해피하우스', '살인교사', '템플러', '직업 : 며느리', '뼈와 재, 불의 이야기', '남편 먹는 여자', '너와 나의 몰디브', '체리 블러드', '모두의 미아씨', '158동 진상부부', '공원여행', '살인범과 산다', '애포칼립스', '미신반신', '의대생 하루', '하나리즈', '식봉툰', '국밥소녀']\n",
    "\n",
    "wt_list=['목요일-연애혁명', '목요일-롤랑롤랑', '금요일-고래별', '금요일-외모지상주의', '수요일-고수', '수요일-귀곡의문', '월요일-뷰티풀군바리', '월요일-유일무이로맨스', '일요일-싸움독학', '일요일-이번생도잘부탁해', '토요일-어글리후드', '토요일-호랑이형님', '화요일-숲속의담', '화요일-여신강림']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df_counter = pd.DataFrame()\n",
    "second_df_counter = pd.DataFrame()\n",
    "third_df_counter = pd.DataFrame()\n",
    "wt_df_counter = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df_counter10 = pd.DataFrame()\n",
    "second_df_counter10 = pd.DataFrame()\n",
    "third_df_counter10 = pd.DataFrame()\n",
    "wt_df_counter10 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in first_group:\n",
    "    for i in range(len(first_df)):\n",
    "        tolist = first_df[j].to_list()\n",
    "        tolist = Counter(tolist)\n",
    "        common_cl = tolist.most_common()\n",
    "        del common_cl[0]\n",
    "    new_col = pd.Series(common_cl, name=j)\n",
    "    first_df_counter = pd.concat([first_df_counter, new_col], axis=1)\n",
    "\n",
    "for j in second_group:\n",
    "    for i in range(len(second_df)):\n",
    "        tolist = second_df[j].to_list()\n",
    "        tolist = Counter(tolist)\n",
    "        common_cl = tolist.most_common()\n",
    "        del common_cl[0]\n",
    "    new_col = pd.Series(common_cl, name=j)\n",
    "    second_df_counter = pd.concat([second_df_counter, new_col], axis=1)\n",
    "\n",
    "for j in third_group:\n",
    "    for i in range(len(third_df)):\n",
    "        tolist = third_df[j].to_list()\n",
    "        tolist = Counter(tolist)\n",
    "        common_cl = tolist.most_common()\n",
    "        del common_cl[0]\n",
    "    new_col = pd.Series(common_cl, name=j)\n",
    "    third_df_counter = pd.concat([third_df_counter, new_col], axis=1)\n",
    "\n",
    "for j in wt_list:\n",
    "    for i in range(len(wt_df)):\n",
    "        tolist = wt_df[j].to_list()\n",
    "        tolist = Counter(tolist)\n",
    "        common_cl = tolist.most_common()\n",
    "        del common_cl[0]\n",
    "    new_col = pd.Series(common_cl, name=j)\n",
    "    wt_df_counter = pd.concat([wt_df_counter, new_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in first_group:\n",
    "    for i in range(len(first_df)):\n",
    "        tolist = first_df[j].to_list()\n",
    "        tolist = Counter(tolist)\n",
    "        common_cl = tolist.most_common(11)\n",
    "        del common_cl[0]\n",
    "    new_col = pd.Series(common_cl, name=j)\n",
    "    first_df_counter10 = pd.concat([first_df_counter10, new_col], axis=1)\n",
    "\n",
    "for j in second_group:\n",
    "    for i in range(len(second_df)):\n",
    "        tolist = second_df[j].to_list()\n",
    "        tolist = Counter(tolist)\n",
    "        common_cl = tolist.most_common(11)\n",
    "        del common_cl[0]\n",
    "    new_col = pd.Series(common_cl, name=j)\n",
    "    second_df_counter10 = pd.concat([second_df_counter10, new_col], axis=1)\n",
    "\n",
    "for j in third_group:\n",
    "    for i in range(len(third_df)):\n",
    "        tolist = third_df[j].to_list()\n",
    "        tolist = Counter(tolist)\n",
    "        common_cl = tolist.most_common(11)\n",
    "        del common_cl[0]\n",
    "    new_col = pd.Series(common_cl, name=j)\n",
    "    third_df_counter10 = pd.concat([third_df_counter10, new_col], axis=1)\n",
    "\n",
    "for j in wt_list:\n",
    "    for i in range(len(wt_df)):\n",
    "        tolist = wt_df[j].to_list()\n",
    "        tolist = Counter(tolist)\n",
    "        common_cl = tolist.most_common(11)\n",
    "        del common_cl[0]\n",
    "    new_col = pd.Series(common_cl, name=j)\n",
    "    wt_df_counter10 = pd.concat([wt_df_counter10, new_col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df_counter.to_csv('1st_counter.csv', index=False, encoding='utf-8-sig')\n",
    "second_df_counter.to_csv('2nd_counter.csv', index=False, encoding='utf-8-sig')\n",
    "third_df_counter.to_csv('3rd_counter.csv', index=False, encoding='utf-8-sig')\n",
    "wt_df_counter.to_csv('wt_counter.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df_counter10.to_csv('1st_counter_10.csv', index=False, encoding='utf-8-sig')\n",
    "second_df_counter10.to_csv('2nd_counter_10.csv', index=False, encoding='utf-8-sig')\n",
    "third_df_counter10.to_csv('3rd_counter_10.csv', index=False, encoding='utf-8-sig')\n",
    "wt_df_counter10.to_csv('wt_counter_10.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}